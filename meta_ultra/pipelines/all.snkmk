import sys
import os.path
import os
from glob import glob
import meta_ultra.config as mup_config
from  meta_ultra.data_type import *
from  meta_ultra.sample_type import *
from meta_ultra.database import RecordExistsError
import json

################################################################################
#
# Setup
#
################################################################################

# Snakemake sometimes transmits a blank config object to
# remote worker nodes. This loads a statically stored version of
# the config as a slightly hacky work around.
if len(config.keys()) == 0:
	confFile = mup_config.snakemake_static_conf_file()
	config = json.loads( open(confFile).read())


if not os.path.isdir(config['OUTPUT_DIR']):
	os.mkdir(config['OUTPUT_DIR'])

output_builders = []

################################################################################
#
# I/O Utilities
#
################################################################################

def getReads(wildcards):
	reads = []
	sample = wildcards.sample
	dataRec = wildcards.data_name
	dataConf = config['SAMPLES'][sample][dataRec]
	dataType = config['SAMPLES'][sample][dataRec]['DATA_TYPE']
	dataType = DataType.asDataType(dataType)
	if dataType == DataType.WGS_DNA_SEQ_SINGLE_END:
		reads.append(dataConf['1'])
		
	elif dataType == DataType.WGS_DNA_SEQ_PAIRED_END:
		reads.append(dataConf['1'])
		reads.append(dataConf['2'])

	return reads

def getNotHostReads(wc):
	if 'FILTER_HOST' not in config['TOOLS_TO_RUN']:
		return getReads(wc)

	dataType = getDataType(wc.sample, wc.data_name)
	reads = []
	if dataType == DataType.WGS_DNA_SEQ_SINGLE_END:
		pattern = config['OUTPUT_DIR']+'{sample}.{data_name}_not-host.fastq.gz'
		reads.append( pattern.format(sample=wc.sample, data_name=wc.data_name))
		
	elif dataType == DataType.WGS_DNA_SEQ_PAIRED_END:
		pattern = config['OUTPUT_DIR']+'{sample}.{data_name}_not-host_{num}.fastq.gz'
		reads.append( pattern.format(sample=wc.sample, data_name=wc.data_name, num=1))
		reads.append( pattern.format(sample=wc.sample, data_name=wc.data_name, num=2))

	return reads

def getHostReads(wc):
	if 'FILTER_HOST' not in config['TOOLS_TO_RUN']:
		return getReads(wc)

	dataType = getDataType(wc.sample, wc.data_name)
	reads = []
	if dataType in [DataType.SR_WMGS_DNA_SINGLE_END,
                        DataType.LR_WMGS_ONT_DNA]:
		pattern = config['OUTPUT_DIR']+'{sample}.{data_name}_host.fastq.gz'
		reads.append( pattern.format(sample=wc.sample, data_name=wc.data_name))
		
	elif dataType in [DataType.SR_WMGS_DNA_PAIRED_END]:
		pattern = config['OUTPUT_DIR']+'{sample}.{data_name}_host_{num}.fastq.gz'
		reads.append( pattern.format(sample=wc.sample, data_name=wc.data_name, num=1))
		reads.append( pattern.format(sample=wc.sample, data_name=wc.data_name, num=2))

	return reads



def getDataType(sampleName, dataName):
	dataConf = config['SAMPLES'][sampleName][dataName]
	dataType = DataType.asDataType(dataConf['DATA_TYPE'])
	return dataType

def getSampleType(sampleName, dataName):
	dataConf = config['SAMPLES'][sampleName][dataName]
	sampleType = SampleType.asSampleType(dataConf['SAMPLE_TYPE'])
	return sampleType


def all_input(wildcards):
	tools = config['TOOLS_TO_RUN']
	inp = []
	for output_builder in output_builders:
		inp += output_builder( wildcards)

        inp = clearExisting(inp)
	return inp

def loadFiles(inputs, outputs, cmd):
	tmpDirCheck = '[ -z "$TMPDIR" ] && TMPDIR=/tmp ; '
	uploadCmds = []
	for i, inp in enumerate(inputs):
		cpCmd = 'rsync -av {} $TMPDIR && I{}='.format(inp,i)
		cpCmd += '${{TMPDIR}}/`basename '+inp+'`'
		uploadCmds.append( cpCmd)

	downloadVars = []
	downloadCmds = []
	for i, outp in enumerate(outputs):
		varCmd = 'O{}='.format(i) + '${{TMPDIR}}/'+'`basename {}`'.format(outp)
		downloadVars.append(varCmd)
		cpCmd = 'rsync -av $O{} {}'.format(i, outp)
		downloadCmds.append(cpCmd)

	uploadCmd = ' && '.join(uploadCmds)
	downloadVar = ' && '.join(downloadVars)
	downloadCmd = ' && '.join(downloadCmds)

	fullCmd =  tmpDirCheck + uploadCmd + ' && ' + downloadVar + ' && ' + cmd + ' && ' + downloadCmd

	print(fullCmd)
	return fullCmd

def prependOutputDir(filename, sampleName=None, dataName=None, generic=True):
        if not generic:
	        pattern = '{}/{}/{}/{}'.format(config['OUTPUT_DIR'], sampleName, dataName, filename)
        else:
                pattern = '{odir}/{{sample}}/{{data_name}}/{fname}'.format(odir=config['OUTPUT_DIR'],
                                                                           fname=filename)
        return pattern

def clearExisting(files):
        return [f for f in files if not os.path.isfile(f)]

def jobName(moduleName, sampleName, dataName):
        pass

def confValOrNone(*keys):
        el = config
        try:
                for key in keys:
                        el = el[key]
                return el
        except KeyError:
                pass
        return None

def getDataSamplePairs( *allowedDataTypes):
	dataSamplePairs=[]
	for sampleName, dataRecords in config['SAMPLES'].items():
		for dataName, dataConf in dataRecords.items():
			dataType = DataType.asDataType(dataConf['DATA_TYPE'])
			if dataType in allowedDataTypes:
				dataSamplePairs.append( (sampleName, dataConf['DATA_NAME']))
        return dataSamplePairs

def standardOutputFileBuilder(pattern, *dataTypes):
	dataNames=getDataSamplePairs(*dataTypes)
        inp = []
        for sample, data in dataNames:
		oFile = finalPattern.format(sample=sample, data_name=data)
                inp.append(oFile)

	return inp
        
################################################################################
#
# Filename Patterns
#
################################################################################

hostVCFPattern = prependOutputDir('{sample}.{data_name}.host.vcf')
hostVCFSortedBAMPattern = prependOutputDir('{sample}.{data_name}.sorted.host.bam')
hostVCFReadGroupBAMPattern = prependOutputDir('{sample}.{data_name}.rg_sorted.host.bam')
hostVCFFlagPattern = hostvcfPattern + '.registered'

mp2Pattern = prependOutputDir('{sample}.{data_name}'+config['METAPHLAN2']['EXT'])
mp2FlagPattern = mp2Pattern + '.registered'

hmpPattern=prependOutputDir('{sample}.{data_name}.hmp_site_dists.json')
hmpFlagPattern = hmpPattern + '.registered'

krakenRawPattern = prependOutputDir('{sample}.{data_name}.' + config['KRAKEN']['RAW_EXT'])
krakenPattern = prependOutputDir('{sample}.{data_name}.'+config['KRAKEN']['MPA_EXT'])
krakenFlagPattern = krakenPattern + '.registered'    

hostSingleReads = prependOutputDir('{sample}.{data_name}_host.fastq.gz')
notHostSingleReads = prependOutputDir('{sample}.{data_name}_not-host.fastq.gz')
hostPaired1Reads = prependOutputDir('{sample}.{data_name}_host_1.fastq.gz')
hostPaired2Read = prependOutputDir('{sample}.{data_name}_host_2.fastq.gz')
notHostPaired1Reads = prependOutputDir('{sample}.{data_name}_not-host_1.fastq.gz')
notHostPaired2Reads = prependOutputDir('{sample}.{data_name}_not-host_2.fastq.gz')
hostBAM = prependOutputDir('{sample}.{data_name}.single_host.bam')
hostFlagPattern = prependOutputDir('{sample}.{data_name}.filter_host.complete')

    
################################################################################
#
# Modular Pipelines
#
################################################################################


snakefiles = {
        "SHORTBRED": 'shortbred.snkmk',
        "METAPHLAN2": 'metaphlan2.snkmk',
        "KRAKEN": 'kraken.snkmk',
        "MASH" : 'mash.snkmk',
        "MICROBE_CENSUS": 'microbe_census.snkmk',
        "FILTER_HOST": 'filter_host.snkmk',
        "HUMANN2": 'humann2.snkmk',
        "COUNT_CLASSIFIED": 'count_classified.snkmk',
        "FOOD_PETS": 'food_and_pets.snkmk',
        "HMP_SITE_DISTS": 'hmp_site_dists.snkmk',
        "HOST_VCF": 'host_vcf.snkmk'
        }

for moduleName, snakefile in snakefiles.items():
        if moduleName in config['TOOLS_TO_RUN']:
                include: snakefile

rule all:
	input:
		all_input

